{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face detection\n",
    "**Members**: <br>\n",
    "Abo, Emmanuel <br>\n",
    "Alferos, Joshua <br>\n",
    "Almodiel, Mj Spencer <br>\n",
    "Aquino, Manolito <br>\n",
    "Baconawa, Joshua <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "names = ['abo', 'juswa', 'spencer', 'baconawa']\n",
    "path = r'faces'\n",
    "haar_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')   # load a pre-trained Haar Cascade classifier for \n",
    "                                                                                                    # face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Features: 82, Length of Labels: 82\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "labels = []\n",
    "def trainData():\n",
    "    for idx, person in enumerate(names):\n",
    "        pic = os.path.join(path, person)\n",
    "        label = idx\n",
    "\n",
    "        for img in os.listdir(pic):\n",
    "            img_path = os.path.join(pic, img)\n",
    "            img_array = cv.imread(img_path)\n",
    "            gray = cv.cvtColor(img_array, cv.COLOR_BGR2GRAY)\n",
    "            \n",
    "            face_rect = haar_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=4)\n",
    "\n",
    "            for (x,y,w,h) in face_rect:\n",
    "                face_roi = gray[y:y+h, x:x+w]\n",
    "                features.append(face_roi)\n",
    "                labels.append(label)\n",
    "trainData()\n",
    "print(f'Length of Features: {len(features)}, Length of Labels: {len(labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "face_recog = cv.face.LBPHFaceRecognizer_create()\n",
    "labels = np.array(labels, dtype=np.int32)\n",
    "#Train the features\n",
    "face_recog.train(features, labels)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_threshold = 80\n",
    "# Open a connection to the webcam (0 represents the default camera)\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=7, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Crop the face region from the frame\n",
    "        face_roi = gray[y:y + h, x:x + w]\n",
    "\n",
    "        # Recognize the face using the LBPH recognizer\n",
    "        label, confidence = face_recog.predict(face_roi)\n",
    "\n",
    "        # Draw a rectangle around the face and display the label and confidence\n",
    "        if confidence < confidence_threshold:\n",
    "            label_text = f'Label: {names[label]}'\n",
    "        else:\n",
    "            label_text = 'Unknown'\n",
    "\n",
    "        cv.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv.putText(frame, label_text, (x, y - 10), cv.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        cv.putText(frame, f'Confidence: {confidence}', (x, y + h + 30), cv.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv.imshow('Face Recognition', frame)\n",
    "\n",
    "    # Break the loop when 'q' key is pressed\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all windows\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
